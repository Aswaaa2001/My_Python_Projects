{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMTZ62eIf5sLt9LQWdhfIxd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aswaaa2001/My_Python_Projects/blob/main/Task1%262.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "anNeKesbuPK3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import pprint\n",
        "from typing import List, Dict, Optional, Any\n",
        "import openai\n",
        "import jsonschema\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GROQ_API_KEY = os.environ.get(\"GROQ_API_KEY\")\n",
        "if not GROQ_API_KEY:\n",
        "    GROQ_API_KEY = input(\"Paste your Groq API key (will not be saved): \").strip()\n",
        "\n",
        "openai.api_key = GROQ_API_KEY\n",
        "openai.api_base = os.environ.get(\"GROQ_API_BASE\", \"https://api.groq.com/openai/v1\")\n",
        "print(\"API configured:\", openai.api_base)"
      ],
      "metadata": {
        "id": "gdFBmfokue_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConversationManager:\n",
        "    def __init__(self, model=\"groq-llm-1\", max_turns=None, max_chars=None, summary_interval=3):\n",
        "        self.model = model\n",
        "        self.max_turns = max_turns\n",
        "        self.max_chars = max_chars\n",
        "        self.summary_interval = summary_interval\n",
        "        self.history: List[Dict[str, str]] = []\n",
        "        self.summaries: List[dict] = []\n",
        "        self.run_count = 0\n",
        "\n",
        "    def add_message(self, role: str, content: str):\n",
        "        self.history.append({\"role\": role, \"content\": content})\n",
        "        self.run_count += 1\n",
        "        self.truncate_history()\n",
        "        if self.run_count % self.summary_interval == 0:\n",
        "            self.summarize_history()\n",
        "\n",
        "    def truncate_history(self):\n",
        "        if self.max_turns:\n",
        "            self.history = self.history[-self.max_turns:]\n",
        "        if self.max_chars:\n",
        "            total = sum(len(m[\"content\"]) for m in self.history)\n",
        "            while total > self.max_chars and len(self.history) > 1:\n",
        "                removed = self.history.pop(0)\n",
        "                total -= len(removed[\"content\"])\n",
        "\n",
        "    def summarize_history(self):\n",
        "        conversation_text = \"\\n\".join(f\"{m['role']}: {m['content']}\" for m in self.history)\n",
        "\n",
        "        functions = [\n",
        "            {\n",
        "                \"name\": \"structured_summary\",\n",
        "                \"description\": \"Summarize the conversation concisely.\",\n",
        "                \"parameters\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"properties\": {\n",
        "                        \"short_summary\": {\"type\": \"string\"},\n",
        "                        \"key_points\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n",
        "                    },\n",
        "                    \"required\": [\"short_summary\"]\n",
        "                }\n",
        "            }\n",
        "        ]\n",
        "\n",
        "        try:\n",
        "            response = openai.ChatCompletion.create(\n",
        "                model=self.model,\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"Summarize the conversation concisely in JSON.\"},\n",
        "                    {\"role\": \"user\", \"content\": conversation_text}\n",
        "                ],\n",
        "                functions=functions,\n",
        "                function_call={\"name\": \"structured_summary\"},\n",
        "                temperature=0.2,\n",
        "                max_tokens=400\n",
        "            )\n",
        "            payload = response.choices[0].message.get(\"function_call\", {}).get(\"arguments\", \"{}\")\n",
        "            parsed = json.loads(payload)\n",
        "        except Exception as e:\n",
        "            parsed = {\"short_summary\": f\"Error: {e}\", \"key_points\": []}\n",
        "\n",
        "        self.summaries.append(parsed)\n",
        "        self.history = [{\"role\": \"system\", \"content\": \"Summary: \" + parsed[\"short_summary\"]}]\n",
        "\n",
        "    def show_history(self):\n",
        "        return self.history\n",
        "\n",
        "    def show_summaries(self):\n",
        "        return self.summaries\n"
      ],
      "metadata": {
        "id": "2-CnVe23ujh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pp = pprint.PrettyPrinter(indent=2)\n",
        "\n",
        "cm = ConversationManager(max_turns=4, max_chars=200, summary_interval=3)\n",
        "\n",
        "samples = [\n",
        "    (\"user\", \"Hello assistant, how are you?\"),\n",
        "    (\"assistant\", \"I’m fine, how can I help you today?\"),\n",
        "    (\"user\", \"Tell me about AI.\"),\n",
        "    (\"assistant\", \"AI stands for Artificial Intelligence.\"),\n",
        "    (\"user\", \"Okay, summarize AI in one sentence.\"),\n",
        "    (\"assistant\", \"AI is machines performing tasks like humans.\")\n",
        "]\n",
        "\n",
        "for role, msg in samples:\n",
        "    print(f\"\\nAdding: {role} → {msg}\")\n",
        "    cm.add_message(role, msg)\n",
        "    print(\"History:\", cm.show_history())\n",
        "\n",
        "print(\"\\nSummaries:\")\n",
        "pp.pprint(cm.show_summaries())\n"
      ],
      "metadata": {
        "id": "746FNUBmupPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "info_schema = {\n",
        "    \"type\": \"object\",\n",
        "    \"properties\": {\n",
        "        \"name\": {\"type\": [\"string\", \"null\"]},\n",
        "        \"email\": {\"type\": [\"string\", \"null\"], \"format\": \"email\"},\n",
        "        \"phone\": {\"type\": [\"string\", \"null\"]},\n",
        "        \"location\": {\"type\": [\"string\", \"null\"]},\n",
        "        \"age\": {\"type\": [\"integer\", \"null\"]}\n",
        "    },\n",
        "    \"required\": [\"name\", \"email\", \"phone\", \"location\", \"age\"]\n",
        "}\n",
        "\n",
        "functions_info_extraction = [\n",
        "    {\n",
        "        \"name\": \"extract_user_info\",\n",
        "        \"description\": \"Extract structured user details from the chat.\",\n",
        "        \"parameters\": info_schema\n",
        "    }\n",
        "]\n",
        "\n",
        "def extract_info_from_chat(chat_text: str, model=\"groq-llm-1\") -> dict:\n",
        "    try:\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=model,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"Extract details and return JSON according to schema.\"},\n",
        "                {\"role\": \"user\", \"content\": chat_text}\n",
        "            ],\n",
        "            functions=functions_info_extraction,\n",
        "            function_call={\"name\": \"extract_user_info\"},\n",
        "            temperature=0.2,\n",
        "            max_tokens=300\n",
        "        )\n",
        "        payload = response.choices[0].message.get(\"function_call\", {}).get(\"arguments\", \"{}\")\n",
        "        parsed = json.loads(payload)\n",
        "        jsonschema.validate(instance=parsed, schema=info_schema)\n",
        "        return parsed\n",
        "    except Exception as e:\n",
        "        print(\"Error:\", e)\n",
        "        return {}\n"
      ],
      "metadata": {
        "id": "lQNy_Dazuxcy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_chats = [\n",
        "    \"Hi, I'm John Doe. You can reach me at john.doe@example.com or call 9876543210. I live in Bangalore and I’m 28 years old.\",\n",
        "    \"My name is Aisha, I’m 35, from Kochi. Email is aisha_kochi@mail.com.\",\n",
        "    \"Hey, just wanted to ask something. I’m Rahul, no email for now, phone 9123456789, living in Delhi.\"\n",
        "]\n",
        "\n",
        "for i, chat in enumerate(sample_chats, start=1):\n",
        "    print(f\"\\n=== Sample Chat {i} ===\")\n",
        "    print(\"Chat:\", chat)\n",
        "    extracted = extract_info_from_chat(chat)\n",
        "    print(\"Extracted JSON:\", json.dumps(extracted, indent=2))\n"
      ],
      "metadata": {
        "id": "yPk206WdwmxX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "export = {\n",
        "    \"task1_summaries\": cm.show_summaries(),\n",
        "    \"task2_samples\": [extract_info_from_chat(c) for c in sample_chats]\n",
        "}\n",
        "with open(\"results.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(export, f, indent=2)\n",
        "print(\"Results saved → results.json\")\n"
      ],
      "metadata": {
        "id": "-f6VCxpMwpzb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}